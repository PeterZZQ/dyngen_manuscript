---
title: "dyngen: benchmarking with in silico single cells"
author:
- Robrecht Cannoodt
- Wouter Saelens
- Louise Deconinck
- Yvan Saeys
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    keep_tex: yes
    latex_engine: xelatex
    citation_package: biblatex
biblatexoptions: sorting=none
classoption:
- table
- 10pt
- a4paper
header-includes: |
  \usepackage{tcolorbox}
  \usepackage{colortbl}
  \usepackage{booktabs}
  \usepackage{tabularx}
  \usepackage{fontspec}
  \setmainfont [Path = fonts/,
    UprightFont = *-300,
    ItalicFont = *-300-Italic,
    BoldFont = *-700,
    BoldItalicFont = *-700-Italic
  ]{MuseoSans}
bibliography: library.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse=TRUE, results="hold")
library(tidyverse)
```

**Purpose:** A common problem of pioneering computational tools is that during their development, there are rarely sufficient datasets available for adequately quantitatively assessing its performance.  
**Results:** We developed dyngen, a multi-modality simulator of single cells. In dyngen, the biomolecular state of an _in silico_ cell changes over time according to a set of reactions defined by the cell's gene regulatory network. By simulating single cells in terms of its biomolecular state and reactions, the simulator is easily extendible for adding new modalities or experimental procedures. We demonstrate dyngen's flexibility by simulating snapshot, time-series and perturbation experiments.  
**Conclusion:** dyngen lays the foundations for benchmarking a wide variety of computational single-cell tools and can be used to help kick-start the development of future types of analyses.

**Author contributions:**

* W.S. and R.C. designed the study.
* R.C., W.S., and L.D. performed the experiments and analysed the data.
* R.C. and W.S. implemented the dyngen software package.
* R.C. and W.S. wrote the original manuscript.
* L.D. wrote the section on trajectory alignment.
* R.C., W.S., L.D., and Y.S. reviewed and edited the manuscript.
* Y.S. supervised the project.

# Introduction {#sec:dyngen-introduction}
Continuous technological advancements to single-cells omics are having profound effects on how researchers can validate biological hypotheses. Early experimental technologies typically only allowed profiling a single modality (e.g. DNA sequence, RNA or protein expression). However, recent developments permit profiling multiple modalities simultaneously, and every modality added allows for new types of analyses that can be performed.

This presents method developers with a problem. The majority of the 250+ peer-reviewed computational tools for analysing single cell omics data were published without a quantitative assessment of the accuracy of the tool. This is partially due to low availability of suitable benchmarking datasets; even if there are sufficient suitable input datasets available, these are often not accompanied by the necessary metadata to serve as ground-truth for a benchmark.

Here, synthetic data plays a crucial role in asserting minimum performance requirements for novel tools in anticipation of adequate real data. Generators of scRNA-seq data (e.g. splatter[@zappia_splattersimulationsinglecell_2017], powsimR[@vieth_powsimrpoweranalysis_2017], PROSSTT[@papadopoulos_prossttprobabilisticsimulation_2018] and SymSim[@zhang_simulatingmultiplefaceted_2019]) have already been widely used to explore the strengths and weaknesses of computational tools, both by method developers[@street_slingshotcelllineage_2018; @parra_reconstructingcomplexlineage_2018; @lummertzdarocha_reconstructioncomplexsinglecell_2018; @lin_scclassifyhierarchicalclassification_2019] and independent benchmarkers[@duo_systematicperformanceevaluation_2018; @saelens_comparisonsinglecelltrajectory_2019; @soneson_biasrobustnessscalability_2018].
However, a limitation of scRNA-seq profiles generators is that they would require significant methodological alterations to add additional modalities or experimental conditions.



An ideal experiment would be able to observe all aspects of a cell, including a full history of its molecular states, spatial positions and environmental interactions[@stuart_integrativesinglecellanalysis_2019].
While this falls outside the reach of current experimental technologies, generating synthetic data in anticipation of new experimental technologies would allow already developing the next wave of computational tools.

We developed a multi-modality simulator of single cells called dyngen (Figure\ \ref{fig:showcase}A). dyngen uses Gillespie's stochastic simulation algorithm[@gillespie_exactstochasticsimulation_1977]  to simulate gene regulatory interactions at a single-molecule level. Its methodology allows tracking of many layers of information throughout the simulation, including the abundance of any molecule in the cell, progression of the cell along a dynamic process, and the activation strength of individual regulatory interactions. dyngen can simulate a large variety of dynamic processes (e.g. cyclic, branching, disconnected) as well as a broad range of experimental conditions (e.g. batch effects and time-series, perturbation and knockdown experiments). The fine-grained controls over simulation parameters allow dyngen to be applicable to a broad range of use-cases. We demonstrate this by performing first quantitative evaluations of three types of novel computational approaches: RNA velocity, casewise network inference and trajectory alignment methods.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\linewidth]{fig/showcase_4}
    \caption{
        \textbf{Showcase of dyngen functionality.}
        \textbf{A:} The typical process of generating a dataset with dyngen.
        \textbf{B:} Evaluating different types of computational tools requires simulating different types of experiments and extracting different layers of information from the simulation.
    }
    \label{fig:showcase}
\end{figure}

# Results {#sec:dyngen-results}

A cell consists of a set of molecules, the abundance of which are affected by a set of reactions: transcription, splicing, translation, and degradation (Figure\ \ref{fig:simplecyclic}A). A gene regulatory network (GRN) defines the reactions that are allowed to occur (Figure\ \ref{fig:simplecyclic}B), which is constructed in such a way that cells slowly develop over time (Figure\ \ref{fig:simplecyclic}C,D). With every time step $\text{d}t$ in the simulation, the probability of a reaction occurring is computed (not shown). From the probabilities are sampled which reactions occur during this time step $\text{d}t$ (Figure\ \ref{fig:simplecyclic}E). 

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\linewidth]{fig/simplecyclic_edited}
    \caption{
        \textbf{dyngen models reactions at a single-molecule level and keeps track of multiple levels of information throughput a simulation.} 
        \textbf{A:} Changes in abundance levels are driven strictly these gene regulatory reactions.
        \textbf{B:} The input GRN is defined such that it models a dynamic process of interest.
        \textbf{C:} The reactions define how abundance levels of molecules change at any particular timepoint.
        \textbf{D:} Firing many reactions can significantly alter the cellular state over time.
        \textbf{E:} dyngen keeps track of the reactions that were fired during small intervals of time.
        \textbf{F:} Similarly, dyngen can also keep track of the regulatory activity of every interaction.
    }
    \label{fig:simplecyclic}
\end{figure}


dyngen returns many modalities throughout the whole simulation: molecular abundance, cellular state, number of reaction firings, reaction likelihoods, and regulation activations (Figure\ \ref{fig:simplecyclic}C--F). These modalities can serve both as input data and ground truth for benchmarking many types of computational approaches. For example, a network inference method could use mRNA abundance and cellular states as inputs and its output could be benchmarked against the gold standard GRN.

Depending on how the GRN is designed, different cellular developmental processes can be simulated.
dyngen includes generators of GRNs which result in many different developmental topologies (Figure\ \ref{fig:example_runs}), including branching, converging, cyclic and even disconnected. Custom-defined GRNs offer more fine-grained control over the simulation.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{fig/example_runs_2}
    \caption{
        \textbf{Multiple executions of dyngen with different predefined backbones.} From each simulation of about 200 genes, 1000 cells were sampled.
        \textbf{A:}~Linear. \textbf{B:}~Bifurcating. \textbf{C:}~Converging.
        \textbf{D:}~Cyclic. \textbf{E:}~Bifurcating loop. \textbf{F:}~Bifurcating converging.
        \textbf{G:}~Consecutive branching. \textbf{H:}~Binary tree. \textbf{I:}~Disconnected.
    }
    \label{fig:example_runs}
\end{figure}


Together, these qualities allow it to be applicable in benchmarking a broad range of use-cases. To demonstrate, we apply dyngen on several novel computational approaches which have recently had a major impact on how single-cell analyses are performed but for which quantitative assessment of the performance was hitherto lacking.

## Example use cases {#sec:dyngen-example}

### Trajectory alignment

### Casewise network inference

Casewise network inference (CNI) methods\footnote{Other terms are commonly used when dealing with data from a particular source. For example, single-cell NI when applied to single-cell transcriptomics data; sample-specific NI when applied to bulk transcriptomics; patient-derived NI when applied to bulk profiles of patients.} predict not only which transcription factors regulate which target genes (Figure\ \ref{fig:scgrn}A, top left), but also how active each interaction is in every case (Figure\ \ref{fig:scgrn}A). In CNI, a 'case' might be a cell, but it might also refer to a bulk sample.

While a few pioneering CNI approaches have already been developed[@aibar_scenicsinglecellregulatory_2017; @kuijjer_estimatingsamplespecificregulatory_2019; @liu_personalizedcharacterizationdiseases_2016], a quantitative assessment of the performance is hitherto lacking. This is not surprising, as neither real nor in silico datasets of cell-specific or even cell-type-specific interactions exists that is large enough so that it can be used as a ground-truth for evaluating CNI methods.

Since dyngen computes tracks the probability of transcription, temporarily 'knocking down' the expression of a regulator and observing the change in transcription probability. This is a much more accurate ground-truth for regulatory interaction between a regulator and target in comparison to observing the change in transcript abundance levels when knocking down a regulator, as the regulation of the target could be indirect.

We used this ground-truth to compare the performance of three CNI methods  (Figure\ \ref{fig:scgrn}B). We calculated the AUROC and AUPR score -- which are common metrics for NI benchmarking -- for each cell individually. Computing the mean AUROC and AUPR per dataset showed that pySCENIC significantly outperforms LIONESS and SSN.

This comparison could be extended to include analyses on the scalability of execution time w.r.t dataset size, the stability of the results in function of noise, and the usability toward end users.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=.8\linewidth]{fig/network_inference/cni.pdf}
    \caption{
    \textbf{dyngen allows benchmarking Casewise Network Inference (CNI) methods.} 
    \textbf{A:} A cell is simulated using the global gene regulatory network (GRN, top left). However, at any particular state in the simulation, only a fraction of the gene regulatory interactions are active.
    \textbf{B:} CNI methods were executed to predict the regulatory interactions that are active in each cell specifically. Using the ground-truth casewise GRN, the performance of each method was quantified on 14 dyngen datasets. 
    }
    \label{fig:scgrn}
\end{figure}



### RNA velocity

In eukaryotes, a gene is first transcribed to a pre-mRNA, and subsequently spliced into mature mRNA. Because reads coming from both unspliced and spliced transcripts are observed in expression data, the relative ratio between the two can tell us something about which genes are increasing, decreasing or remaining the same[@zeisel_coupledpremrnamrna_2011;@lamanno_rnavelocitysingle_2018]. To determine this, some parameters have to be estimated to determine which fraction of unspliced and spliced mRNAs corresponds to an increase or decrease. The estimation of these parameters makes some assumptions, and can be handled in different ways in the two main algorithms that are now available for RNA velocity estimation: velocyto[@lamanno_rnavelocitysingle_2018] and scvelo[@bergen_generalizingrnavelocity_2019]. It can be difficult to obtain ground truth data to benchmark these algorithms, given that it would require continuous data of transcriptional dynamics in individual cells. On the other hand, the ground truth velocity is rapidly extracted from the dyngen model, by looking whether each transcript is currently increasing or decreasing in expression.

We tested scvelo and velocyto on 8 datasets containing linear, bifurcating, disconnected and cyclic trajectories, and varied the main parameter settings in which they estimate the velocity. We found that the original velocyto implementation, which assumes that the velocity remains constant in some cells, performed the best across all datasets. The dynamical estimation of velocyto, as implemented in scvelo, performed the worst of all parameter settings. This was mainly due to scvelo overestimating the dynamics of a gene, especially towards upregulation, while velocyto correctly estimated not only when a gene changes, but also when it remained in a steady state.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=.8\linewidth]{results/velocity/usecase.pdf}
    \caption{
    \textbf{dyngen allows benchmarking of RNA velocity methods.} 
    \textbf{A:} We tested five different methods and parameter settings for the estimation of RNA velocity on datasets with varying backbones (colors). Overall, the velocyto method with the constant velocity assumption performed the best overall.
    \textbf{B:} An example bifurcating dataset, with as illustration the expression and ground truth velocity of a gene that goes up and down in the trajectory. 
\textbf{C:} The RNA velocity estimates of the different methods.
\textbf{D:} The embedded RNA velocity of the different methods.
    }
    \label{fig:velocity}
\end{figure}


# Discussion {#sec:dyngen-discussion}
As is, dyngen's single cell simulations can be used to evaluate common single-cell omics computational methods such as clustering, batch correction, trajectory inference and network inference.
However, the combined effect of these advantages results in a framework that is flexible enough to adapt to a broad range of applications. This may include methods that integrate clustering, network inference and trajectory inference. In this respect, dyngen may promote the development of new tools in the single-cell field similarly as other simulators have done in the past[@schaffter_genenetweaversilicobenchmark_2011; @ewing_combiningtumorgenome_2015].

dyngen ultimately allows anticipating technological developments in single-cell multi-omics. In this way, it is possible to design and evaluate the performance and robustness of new types of computational analyses before experimental data becomes available.
In addition, it could also be used to compare which experimental protocol is the most cost-effective in producing the qualitative and robust results in downstream analysis.

Currently, dyngen focuses on simulating cells as standalone entities that are well mixed.
Splitting up the simulation space into separate subvolumes could pave the way to better study key cellular processes such as cell division, intercellular communication and migration[@smith_spatialstochasticintracellular_2019].




# Methods {#sec:dyngen-methods}
The workflow to generate _in silico_ single cell data consists of six main steps (Figure\ \ref{fig:explain_methods}).

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{fig/explain_methods}
    \caption{\textbf{The workflow of dyngen is comprised of six main steps.} 
    \textbf{A:} The user needs to specify the desired module network or use a predefined module network. 
    \textbf{B:} Each gene in a module is is regulated by one or more transcription factors from the upstream module. Additional target genes are generated. 
    \textbf{C:} Each gene regulatory interaction in the GRN is converted to a set of biochemical reactions. 
    \textbf{D:} Along with the module network, the user also needs to specify the backbone structure of expected cell states. The average expression of each edge in the backbone is simulated by activating a restricted set of genes for each edge. 
    \textbf{E:} Multiple Gillespie SSA simulations are run using the reactions defined in step C.  The counts of each of the molecules at each time step are extracted. Each time step is mapped to a point in the backbone. 
    \textbf{F:} The molecule levels of multiple simulations are shown over time (left). From each simulation, multiple cells are sampled (from left to middle). Technical noise from profiling is simulated by sampling molecules from the set of molecules inside each cell (from middle to right).
    }
    \label{fig:explain_methods}
\end{figure}


## Defining the backbone: modules and states {#sec:dyngen-backbone}

One of the main processes involved in cellular dynamic processes is gene regulation, where regulatory cascades and feedback loops lead to progressive changes in expression and decision making. The exact way a cell chooses a certain path during its differentiation is still an active research field, although certain models have already emerged and been tested _in vivo_. One driver of bifurcation seems to be mutual antagonism, where two genes strongly repress each other[@rekhtman_directinteractionhematopoietic_1999; @xu_regulationbifurcatingcell_2015], forcing one of the two to become inactive[@graf_forcingcellschange_2009]. Such mutual antagonism can be modelled and simulated[@wang_quantifyingwaddingtonlandscape_2011; @ferrell_bistabilitybifurcationswaddington_2012]. Although the two-gene model is simple and elegant, the reality is frequently more complex, with multiple genes (grouped into modules) repressing each other[@yosef_dynamicregulatorynetwork_2013].

To start a dyngen simulation, the user needs to define a module network and a backbone. The module network defines how sets of co-regulated genes, called modules, regulate each other. The module network is what mainly determines which dynamic processes occur within the simulated cells. The backbone is a separate set of simulations in which the ground-truth topology of the dynamic processes are defined, as it is difficult to determine the topology of the dynamic processes from the module network itself.

A module network consists of modules connected together by regulatory interactions. 
A module may have basal expression, which means genes in this module will be transcribed without the presence of transcription factor molecules. A module marked as "active during the burn phase" means that this module will be allowed to generate expression of its genes during an initial warm-up phase (See section \ref{sec:dyngen-simcell}). At the end of the dyngen process, cells will not be sampled from the burn phase simulations. Interactions between modules have a strength (which is a positive integer) and an effect (+1 for upregulating, -1 for downregulating).

Several examples of module networks are given (Figure\ \ref{fig:example_backbones}).
A simple chain of modules (where one module upregulates the next) results in a _linear_ process. By having the last module repress the first module, the process becomes _cyclic_. Two modules repressing each other is the basis of a _bifurcating_ process, though several chains of modules have to be attached in order to achieve progression before and after the bifurcation process. Finally, a \emph{converging} process has a bifurcation occurring during the burn phase, after which any differences in module regulation is removed.

Note that these examples represent the bare minimum in terms of number of modules used. Using longer chains of modules is typically desired. In addition, the fate decisions made in this example of a bifurcation is reversible, meaning cells can be reprogrammed to go down a different differentiation path. If this effect is undesirable, more safeguards need to be put in place to prevent reprogramming from occurring (Section \ref{sec:dyngen-bbl}).

\begin{figure}[htb!]
    \centering
    \includegraphics[width=0.8\textwidth]{fig/example_backbones}
    \caption{
      \textbf{Example module networks.}
    }
    \label{fig:example_backbones}
\end{figure}


In addition to the module network, the user also needs to define a network of cellular states called the "backbone". Before simulating any cells, each transition in the backbone is simulated separately to obtain the average changes in expression along that transition (Figure\ \ref{fig:explain_methods}D). As part of the backbone, the user needs to specify which modules are allowed to alter its expression from one state to another. For example, in order to transition from state S0 to S1 in the cyclic example, gene modules A, B and C are turned on and a simulation is allowed to run. To transition from S1 to S2, gene modules D and E are turned on, and expression of gene module C is kept constant. To transition from S2 to S3, C is turned on again and now A and B are fixed. Finally, to transition from S3 to S1 again, A and B are turned on again and D and E are fixed again. Demonstrations of the backbone will be explained in more detail in section \ref{sec:dyngen-simbackbone}.

### Backbone lego {#sec:dyngen-bbl}
The backbone can make use of one or more "backbone lego" (BBL) pieces (Figure\ \ref{fig:backbone_lego}). A BBL consists of one or more modules which regulate each other such that the output modules present a specific behaviour, depending on the input module (Figure\ \ref{fig:backbone_lego}A). Parameters allow determining the number of modules involved in the process and the number of outputs. Multiple BBLs can be chained together in order to intuitively create module networks and corresponding state networks (Figure\ \ref{fig:backbone_lego}B). Note that not all dynamic processes can be represented by a combination of BBLs, but they can serve as common building blocks to aid the construction of the backbone.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=0.8\textwidth]{fig/backbone_lego}
    \caption{
      \textbf{Backbone lego.}
    }
    \label{fig:backbone_lego}
\end{figure}


When the input node of a **linear BBL** (Figure\ \ref{fig:backbone_lego}C) is upregulated, the module the BBL is connected to will be upregulated. A _simple chain_ is a set of modules where a module upregulates the next. A _chain with double repression_ has an uneven number of modules forming a chain where each module downregulates the next but all modules (except the input) have basal expression. A _grid with double repression_ is similar; except that modules do not have basal expression but instead get upregulated by an upstream module in the chain. Finally, a _flip flop_} consists of a simple chain where first the modules (except the last) are upregulated. Once the second to last module is upregulated, that module upregulates itself and the first module is strongly repressed, causing all other modules to lose expression and finally the last module to be upregulated. The _flip flop_ retains this output state, even when the input changes.

When the input node of a **branching BBL** (Figure\ \ref{fig:backbone_lego}D) is upregulated, a subset of its output modules will eventually be upregulated. A \emph{simple branching} uses reciprocal inhibition to drive the upregulation of one of the output modules. Due to its simplicity, however, multiple output modules might be upregulated simultaneously and over long periods of simulation time it might be possible that the choice of upregulated module changes. A _robust branching_ improves upon the simple branching by preventing upregulation of output modules until an internal branching decision has been made, and by repressing the decision mechanism to avoid other output modules being upregulated other than the one that has been chosen.

A **leaf BBL** (Figure\ \ref{fig:backbone_lego}E) is a linear BBL that has either no inputs or no outputs. A _start_ BBL is a linear BBL where the first module has basal expression, and all modules in this module will be active during the burn-in phase of the simulation (Section \ref{sec:dyngen-simbackbone}). An _end_ BBL is also a linear BBL with its output regulating one final module.


## Generating the gene regulatory network {#sec:dyngen-grn}
The GRN is generated based on the given backbone in four main steps (Figure\ \ref{fig:gen_feature_network}).

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\linewidth]{fig/gen_feature_network}
    \caption{
        \textbf{Generating the feature network from a backbone consists of four main steps.}
    }
    \label{fig:gen_feature_network}
\end{figure}


**Step 1, sampling the transcription factors (TF).** The TFs are the main drivers of the molecular changes in the simulation. The user provides a backbone and the number of TFs to generate. Each TF is assigned to a module such that each module has at least $x$ parameters (default $x=1$). A TF inherits the 'burn' and 'basal expression' from the module it belongs to.

**Step 2, generating the TF interactions.** Let each TF be regulated according to the interactions in the backbone. These interactions inherit the effect, strength, and cooperativity parameters from the interactions in the backbone. A TF can only be regulated by other TFs or itself.

**Step 3, sampling the target subnetwork.**
A user-defined number of target genes are added to the GRN. Target genes are regulated by a TF or another target gene, but is always downstream of at least one TF. To sample the interactions between target genes, one of the many FANTOM5 \cite{lizio_gatewaysfantom5promoter_2015} GRNs is sampled. The currently existing TFs are mapped to regulators in the FANTOM5 GRN. The targets are drawn from the FANTOM5 GRN, weighted by their page rank value. For each target, at most $x$ regulators are sampled from the induced FANTOM5 GRN (default $x=5$). The interactions connecting a target gene and its regulators are added the GRN.

**Step 4, sampling the housekeeping subnetwork.**
Housekeeping genes are completely separate from any TFs or target genes. A user-defined set of housekeeping genes are also sampled from the FANTOM5 GRN. The interactions of the FANTOM5 GRN are first subsampled such that the maximum in-degree of each gene is $x$ (default $x=5$). A random gene is sampled and a breadth-first-search is performed to sample the desired number of housekeeping genes.

## Convert gene regulatory network to a set of reactions {#sec:dyngen-reactions}

\newcommand{\w}[1]{\text{w}_{#1}}
\newcommand{\x}[1]{\text{x}_{#1}}
\newcommand{\y}[1]{\text{y}_{#1}}


\newcommand{\rs}[1]{\text{R}_{#1}}
\newcommand{\rp}[1]{\text{R}^+_{#1}}
\newcommand{\rn}[1]{\text{R}^-_{#1}}

\newcommand{\wpr}[1]{\text{wpr}_{#1}}
\newcommand{\whl}[1]{\text{whl}_{#1}}
\newcommand{\wdr}[1]{\text{wdr}_{#1}}
\newcommand{\wsr}[1]{\text{wsr}_{#1}}
\newcommand{\xhl}[1]{\text{xhl}_{#1}}
\newcommand{\xdr}[1]{\text{xdr}_{#1}}
\newcommand{\ypr}[1]{\text{ypr}_{#1}}
\newcommand{\yhl}[1]{\text{yhl}_{#1}}
\newcommand{\ydr}[1]{\text{ydr}_{#1}}

\newcommand{\str}[1]{\text{str}_{#1}}
\newcommand{\hill}[1]{\text{hill}_{#1}}
\newcommand{\coop}[1]{\text{co}_{#1}}
\newcommand{\dis}[1]{\text{dis}_{#1}}
\newcommand{\buf}[1]{\chi_{#1}}
\newcommand{\ba}[1]{\text{ba}_{#1}}

Simulating a cell's GRN makes use of a stochastic framework which tracks the abundance levels of molecules over time in a discrete quantity. For every gene $G$, the abundance levels of three molecules are tracked, namely of corresponding pre-mRNAs, mature mRNAs and proteins, which are represented by the terms $\w G$, $\x G$ and $\y G$ respectively. The GRN defines how a reaction affects the abundance levels of molecules and how likely it will occur. Gibson and Bruck[@gibson_probabilisticmodelprokaryotic_2000] provide a good introduction to modelling gene regulation with stochastic frameworks, on which many of the concepts below are based.

For every gene in the GRN a set of reactions are defined, namely transcription, splicing, translation, and degradation. Each reaction consists of a propensity function -- a formula $f(.)$ to calculate the probability $f(.) \times \text{d}t$ of it occurring during a time interval $\text{d}t$ -- and the effect -- how it will affect the current state if triggered. 

The effects of each reaction mimic the respective biological processes (Table\ \ref{tab:reaction_def}, middle). Transcription of gene $G$ results in the creation of a single pre-mRNA molecule $\w G$. Splicing turns one pre-mRNA $\w G$ into a mature mRNA $\w G$. Translation uses a mature mRNA $\x G$ to produce a protein $\y G$. Pre-mRNA, mRNA and protein degradation results in the removal of a $\w G$, $\x G$, and $\y G$ molecule, respectively.

The propensity of all reactions except transcription are all linear functions (Table\ \ref{tab:reaction_def}, right) of the abundance level of some molecule multiplied by a constant drawn from a normal distribution (Table\ \ref{tab:reaction_params}). The propensity of transcription of a gene $G$ depends on the abundance levels of its TFs. 



\begin{table}[ht]
    \caption{
      \textbf{Reactions affecting the abundance levels of pre-mRNA $\w G$, mature mRNA $\x G$ and proteins $\y G$ of gene $G$.} Define the set of regulators of $G$ as $\rs{G}$, the set of upregulating regulators of $G$ as $\rp G$, and the set of downregulating regulators of $G$ as $\rn G$. Parameters used in the propensity formulae are defined in Table \ref{tab:reaction_params}.
    } \label{tab:reaction_def}
    \centering
    \begin{tabular}{|lcc|}
        \hline
        Reaction & Effect & Propensity \\ \hline \hline
        Transcription & $\emptyset \rightarrow \w G$ & $\wpr G \times \frac{\ba G - \coop{G}^{|\rp{G}|} + \prod\limits_{H \in \rp{G}}(\coop G + \buf{G,H})}{\prod\limits_{H \in \rs{G}}(1 + \buf{G,H})}$ \\
        Pre-mRNA degradation & $\w G \rightarrow \emptyset$ & $\wdr G \times \w G$ \\
        Splicing & $\w G \rightarrow \x G$ & $\wsr G \times \w G$ \\
        Mature mRNA degradation & $\x G \rightarrow \emptyset$ & $\xdr G \times \x G$ \\
        Translation & $\x G \rightarrow \x G + \y G$ & $\ypr G \times \x G$ \\
        Protein degradation & $\y G \rightarrow \emptyset$ & $\ydr G \times \y G$ \\ \hline
    \end{tabular}
\end{table}



\begin{table}[ht]
    \caption{
      \textbf{Default parameters defined for the calculation of reaction propensity functions.}
    } \label{tab:reaction_params}
    \centering
    \begin{tabular}{|lrl|}
        \hline
        Parameter & Symbol & Definition \\ \hline \hline
        Transcription rate & $\wpr{G}$ & $\in N(50, 10),\ \geq 10$ \\
        Splicing rate & $\wsr G$ & $\in N(5, 1),\ \geq 1$ \\
        Translation rate & $\ypr{G}$ & $\in N(5, 1),\ \geq 1$ \\
        Pre-mRNA half-life & $\whl{G}$ & $\in N(0.15, 0.03),\ \geq 0.05$ \\
        Mature mRNA half-life & $\xhl{G}$ & $\in N(0.15, 0.03),\ \geq 0.05$ \\
        Protein half-life rate & $\yhl G$ & $\in N(0.25, 0.05),\ \geq 0.1$ \\
        Interaction strength & $\str{G,H}$ & $\in 10^{U(0, 2)}$ * \\
        Hill coefficient & $\hill{G,H}$ & $\in U(0.5, 2)$ * \\
        Cooperativity factor & $\coop G$ & $\in [0, 1]$ * \\ \hline\hline
        Pre-mRNA degradation rate & $\wdr G$ & $= \ln(2)\ /\ \whl G$ \\
        Mature mRNA degradation rate & $\xdr G$ & $= \ln(2)\ /\ \xhl G$ \\
        Protein degradation rate & $\ydr G$ & $= \ln(2)\ /\ \yhl G$ \\
        Dissociation constant & $\dis H$ & $= 0.5 \times \frac{\wpr H \times \wsr H \times \ypr H}{(\wdr H + \wsr H) \times \xdr H \times \ydr H}$ \\
        Binding & $\buf{G,H}$ & $= \left(\str{G,H} \times \y H\ /\ \dis H\right) ^ {\hill{G,H}}$ \\
        Basal expression & $\ba G$ & $= \begin{cases} 1 & \mbox{if } \rp{G} = \emptyset \\ 0.0001 & \mbox{if } \rn{G} = \emptyset \mbox{ and } \rp{G} \neq \emptyset \\ 0.5 & \mbox{otherwise} \end{cases}$ * \\ \hline
        \multicolumn{3}{l}{*: unless $G$ is a TF, then the value is determined by the backbone.}
    \end{tabular}
\end{table}




\newcommand{\proptran}{f}
\newcommand{\ai}[2]{$S_{#1} = S_{#2b}$}
\newcommand{\yk}[1]{\frac{y_#1}{k_#1}^{c_#1}}
\newcommand{\wi}[1]{\nu_#1}

The propensity of the transcription of a gene $G$ is inspired by thermodynamic models of gene regulation [needcitation], in which the promoter of $G$ can be bound or unbound by a set of $N$ transcription factors $H_i$. Let $\proptran(\y 1, \y 2, \ldots, \y N)$ denote the propensity function of $G$, in function of the abundance levels of the transcription factors. The following subsections explain and define the propensity function when $N=1$, $N=2$, and finally for an arbitrary $N$.

### Propensity of transcription when $N=1$
In the simplest case when $N=1$, the promoter can be in one of two states. In state $S_0$, the promoter is not bound by any transcription factors, and in state $S_1$ the promoter is bound by $H_1$. Each state $S_j$ is linked with a relative activation $\alpha_j$, a number between 0 and 1 representing the activity of the promoter at this particular state. The propensity function is thus equal to the expected value of the activity of the promoter multiplied by the pre-mRNA production rate of $G$.

\begin{align}
  f(y_1, y_2, \ldots, y_N) & = \text{wpr} \cdot \sum_{j = 0}^{2^N - 1} \alpha_j \cdot P(S_j) \label{eqn:activ0} \\
\end{align}

For $N=1$, $P(S_1)$ is equal to the Hill equation, where $k_i$ represents the concentration of $H_i$ at half-occupation and $n_i$ represents the Hill coefficient. Typically, $n_i$ is between [1,10]

\begin{align}
  P(S_1) & = \frac{y_1^{n_1}}{k_1^{n_1} + y_1^{n_1}} \\
     & = \frac{(y_1/k_1)^{n_1}}{1 + (y_1/k_1)^{n_1}}
\end{align}

The Hill equation can be simplified by letting $\nu_i = \left(\frac{y_i}{k_i}\right)^{n_i}$.


\begin{align}
P(S_1) & = \frac{\nu_1}{1 + \nu_1} \label{eqn:hillsimp}
\end{align}

Since $P(S_0) = 1 - P(S_1)$, the activation function is formulated and simplified as follows.


\begin{align}
f(y_1) & = \text{wpr} \cdot \left(\alpha_0 \cdot P(S_0) + \alpha_1 \cdot P(S_1)\right) \\
   & = \text{wpr} \cdot \left(\alpha_0 \cdot \frac{1}{1 + \nu_1} + \alpha_1 \cdot \frac{\nu_1}{1 + \nu_1}\right) \\
   & = \text{wpr} \cdot \frac{\alpha_0 + \alpha_1 \cdot \nu_1}{1 + \nu_1} \\
\end{align}


### Propensity of transcription when $N=2$

When $N=2$, there are four states $S_j$. The relative activations $\alpha_j$ can be defined such that $H_1$ and $H_2$ are independent (additive) or synergistic (multiplicative). In order to define the propensity of transcription $f(.)$, the Hill equation $P(S_j)$ is extended for two transcription factors.

Let $w_j$ be the numerator of $P(S_j)$, defined as the product of all transcription factors bound in that state:

\begin{align}
w_0 & = 1 \\
w_1 & = \nu_1 \\
w_2 & = \nu_2 \\
w_3 & = \nu_1 \cdot \nu_2
\end{align}

The denominator of $P(S_j)$ is then equal to the sum of all $w_j$. The probability of state $S_j$ is thus defined as:

\begin{align}
    P(S_j) & = \frac{w_j}{\sum_{j=0}^{j < 2^N} w_j} \\
       & = \frac{w_j}{1 + \nu_1 + \nu_2 + \nu_1 \cdot \nu_2} \\
       & = \frac{w_j}{\prod_{i=1}^{i \leq N} (\nu_i + 1)}
\end{align}

Substituting $P(S_j)$ and $w_j$ into $f(.)$ results in the following equation:

\begin{align}
f(y_1, y_2) & = \text{wpr} \cdot \sum_{j = 0}^{2^N - 1} \alpha_j \cdot P(S_j) \\
 & = \text{wpr} \cdot \frac{\sum_{j = 0}^{2^N - 1} \alpha_j \cdot w_j}{\prod_{i=1}^{i \leq N} (\nu_i + 1)} \\
 & = \text{wpr} \cdot \frac{\alpha_0 + \alpha_1 \cdot \nu_1 + \alpha_2 \cdot \nu_2 + \alpha_3 \cdot \nu_1 \cdot \nu_2}{(\nu_1 + 1) \cdot (\nu_2 + 1)} \\
\end{align}


### Propensity of transcription for an arbitrary $N$
For an arbitrary $N$, there are $2^N$ states $S_j$. The relative activations $\alpha_j$ can be defined such that $H_1$ and $H_2$ are independent (additive) or synergistic (multiplicative). In order to define the propensity of transcription $f(.)$, the Hill equation $P(S_j)$ is extended for $N$ transcription factors.

Let $w_j$ be the numerator of $P(S_j)$, defined as the product of all transcription factors bound in that state:

\begin{align}
  w_j & = \prod_{i=1}^{i \leq N} (j \text{ mod } i) = 1 \text{ ? } \nu_i \text{ : } 1
\end{align}

The denominator of $P(S_j)$ is then equal to the sum of all $w_j$. The probability of state $S_j$ is thus defined as:

\begin{align}
P(S_j) & = \frac{w_j}{\sum_{j=0}^{j < 2^N} w_j} \\
& = \frac{w_j}{\prod_{i=1}^{i \leq N} (\nu_i + 1)}
\end{align}

Substituting $P(S_j)$ into $f(.)$ yields:

\begin{align}
f(y_1, y_2, \ldots, y_N) & = \text{wpr} \cdot \sum_{j = 0}^{2^N - 1} \alpha_j \cdot P(S_j) \\
& = \text{wpr} \cdot \frac{\sum_{j = 0}^{2^N - 1} \alpha_j \cdot w_j}{\prod_{i=1}^{i \leq N} (\nu_i + 1)} \label{eqn:prop2n}
\end{align}

### Propensity of transcription for a large $N$
For large values of $N$, computing $f(.)$ is practically infeasible as it requires performing $2^N$ summations. In order to greatly simplify $f(.)$, $\alpha_j$ could be defined as 0 when one of the regulators inhibits transcription and 1 otherwise.

\begin{equation}
\alpha_j = \begin{cases}
 0 & \text{ if } \exists i : j \text{ mod } i = 1 \text{ and } H_i \text{ represses } G \\
 1 & \text{otherwise}
\end{cases} \label{eqn:assalpha}
\end{equation}

Substituting equation \ref{eqn:assalpha} into equation \ref{eqn:prop2n} and defining $R = \{1, 2, \ldots, N\}$ and $R^+ = \{i | H_i \text{ activates } G\}$ yields the simplified propensity function:

\begin{align}
f(y_1, y_2, \ldots, y_N) & = \text{wpr} \cdot \frac{\prod_{i \in R^+} (\nu_i + 1)}{\prod_{i \in R} (\nu_i + 1)}
\end{align}

### Independence, synergism and basal expression
The definition of $\alpha_j$ as in equation \ref{eqn:assalpha} presents two main limitations. Firstly, since $\alpha_0 = 1$, it is impossible to tweak the propensity of transcription when no transcription factors are bound. Secondly, it is not possible to tweak the independence and synergism of multiple regulators.

Let $\text{ba} \in [0,1]$ denote the basal expression strength $G$ (i.e. how much will $G$ be expressed when no transcription factors are bound), and $\text{sy} \in [0,1]$ denote the synergism of regulators $H_i$ of $G$, the transcription propensity becomes:

\begin{align}
f(y_1, y_2, \ldots, y_N) & = \text{wpr} \cdot \frac{\text{ba} - \text{sy}^{|R^+|} + \prod_{i \in R^+} (\nu_i + \text{sy})}{\prod_{i \in R} (\nu_i + 1)}
\end{align}


## Compute average expression along backbone transitions {#sec:dyngen-simbackbone}
When simulating the developmental backbone, we go through the edges of the backbone state network defined in an earlier step (Section \ref{sec:dyngen-backbone}), starting from the root state. It is assumed the root state has no modules active and has no expression of any molecules. To get to the next state, we follow a transition starting from the root state, activate and deactivate the modules as indicated by the transition, and compute the average molecule abundance along the transition. To compute the average abundance, we perform small time steps $t = 0.001$ and let each reaction (Section \ref{sec:dyngen-reactions}) occur $t$ times its propensity.


## Simulate single cells {#sec:dyngen-simcell}
dyngen uses Gillespie's stochastic simulation algorithm (SSA)[@gillespie_exactstochasticsimulation_1977] to simulate dynamic processes. An SSA simulation is an iterative process where at each iteration one reaction is triggered.

Each reaction consists of its propensity -- a formula to calculate the probability of the reaction occurring during an infinitesimal time interval -- and the effect -- how it will affect the current state if triggered. Each time a reaction is triggered, the simulation time is incremented by $\tau = \frac{1}{\sum_j prop_j} \ln\left(\frac{1}{r}\right)$, with $r \in U(0, 1)$ and $prop_j$ the propensity value of the $j$th reaction for the current state of the simulation.

GillespieSSA2 is an optimised library for performing SSA simulations. The propensity functions are compiled to C++ and SSA approximations can be used which allow to trigger many reactions simultaneously at each iteration. The framework also allows to store the abundance levels of molecules only after a specific interval has passed since the previous census. By setting the census interval to 0, the whole simulation's trajectory is retained but many of these time points will contain very similar information. In addition to the abundance levels, also the propensity values and the number of firings of each of the reactions at each of the time steps can be retained, as well as specific sub-calculations of the propensity values, such as the regulator activity level $reg_{G,H}$.

### Map SSA simulations to backbone
We compute the Pearson correlation between the state vectors in the simulation and the average expression levels along a transition in the backbone. Each timepoint in the SSA simulation is mapped to the point in the backbone that has the highest correlation value.

## Simulate experiment {#sec:dyngen-experiment}
From the SSA simulation we obtain the abundance levels of all the molecules at every state. We need to replicate technical effects introduced by experimental protocols in order to obtain data that is similar to real data. For this, the cells are sampled from the simulations and molecules are sampled for each of the cells. Real datasets are used in order to achieve similar data characteristics.

### Sample cells
In this step, $N$ cells are sampled the simulations. Two approaches are implemented: sampling from an unsynchronised population of single cells (snapshot) or sampling at multiple time points in a synchronised population (time series).

**Snapshot** The backbone consists of several states linked together by transition edges with length $L_i$, to which the different states in the different simulations have been mapped (Figure\ \ref{fig:sample_cells}A). From each transition, $N_i = N / \frac{L_i}{\sum L_i}$ cells are sampled uniformly, rounded such that $\sum N_i = N$.

**Time series** Assuming that the final time of the simulations is $T$, the interval $[0, T]$ is divided into $k$ equal intervals of width $w$ separated by $k-1$ gaps of width $g$. $N_i = N / k$ cells are sampled uniformly from each interval (Figure\ \ref{fig:sample_cells}B), rounded such that $\sum N_i = N$. By default, $k = 8$ and $g = 0.75$. For usual dyngen simulations, $10 \leq T \leq 20$. For larger values of $T$, $k$ and $g$ should be increased accordingly.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=.6\linewidth]{fig/sample_cells.pdf}
    \caption{
        \textbf{Two approaches can be used to sample cells from simulations: snapshot and time-series.}
    }
    \label{fig:sample_cells}
\end{figure}


### Sample molecules
Molecules are sampled from the simulation to replicate how molecules are experimentally sampled. A real dataset is downloaded from a repository of single-cell RNA-seq datasets[@cannoodt_singlecellomicsdatasets_2018]. For each _in silico_ cell $i$, draw its library size $ls_i$from the distribution of transcript counts per cell in the real dataset. The capture rate $cr_j$ of each _in silico_ molecule type $j$ is drawn from $N(1, 0.05)$. Finally, for each cell $i$, draw $ls_i$ molecules from the multinomial distribution with probabilities $cr_j \times ab_{i,j}$ with $ab_{i,j}$ the molecule abundance level of molecule $j$ in cell $i$.

## Determining the casewise ground-truth regulatory network {#sec:dyngen-extractgrn}
Calculating the regulatory effect of a regulator $R$ on a target $T$ (Figure\ \ref{fig:explain_methods}F) requires determining the contribution of $R$ in the propensity function of the transcription of $T$ (section\ \ref{sec:dyngen-reactions}) with respect to other regulators. This information is useful, amongst others, for benchmarking casewise network inference methods. 

The regulatory effect of $R$ on $T$ at a particular state $S$ is defined as the change in the propensity of transcription when $R$ is set to zero, scaled by the inverse of the pre-mRNA production rate of $T$. More formally:

\begin{eqnarray*}
  \text{regeffect}_G & = \frac{\text{proptrans}_G(S) - \text{proptrans}_G(S[\y T \leftarrow 0])}{\wpr G}
\end{eqnarray*}

Determining the regulatory effect for all interactions and cells in the dataset yields the complete casewise ground-truth GRN (Figure\ \ref{fig:casewise_grn}). The regulatory effect lie between $[-1, 1]$, where -1 represents complete inhibition of $T$ by $R$, 1 represents maximal activation of $T$ by $R$, and 0 represents inactivity of the regulatory interaction between $R$ and $T$.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=.8\linewidth]{fig/small_bifurc/scgrn.pdf}
    \caption{
        \textbf{The casewise regulatory effects of all interactions, computed on cells part of a bifurcation trajectory.} Negative values correspond to inhibitory interactions, positive values to activating interactions, and zero values correspond to inactive interactions. 
    }
    \label{fig:casewise_grn}
\end{figure}


## Comparison of casewise network inference methods {#sec:dyngen-nicompare}
Several datasets were generated using the different predefined backbones. For every cell in the dataset, the transcriptomics profile and the corresponding casewise ground-truth regulatory network was determined (Section\ \ref{sec:dyngen-extractgrn}). 

Several casewise NI methods were considered for comparison: SCENIC[@aibar_scenicsinglecellregulatory_2017], LIONESS[@kuijjer_estimatingsamplespecificregulatory_2015; @kuijjer_estimatingsamplespecificregulatory_2019], and SSN[@liu_personalizedcharacterizationdiseases_2016]. 

LIONESS[@@kuijjer_estimatingsamplespecificregulatory_2019; kuijjer_lionessrsinglesample_2019] uses the Pearson correlation to infer casewise GRNs. To do so, first the Pearson correlation is calculated between regulators and targets for all samples. Next, the Pearson correlation is again calculated for all samples excluding one sample. The difference between the two correlation matrices is considered a casewise GRN for that particular profile. This process is repeated for all profiles, resulting in a casewise GRN.

SSN[@liu_personalizedcharacterizationdiseases_2016] has, in essence, the exact same methodology as LIONESS. It is worth noting that the LIONESS preprint was released before the publication of SSN. Since no implementation was provided by the authors, we implemented SSN in R using basic R and tidyverse functions[@wickham_welcometidyverse_2019] and marked results from this implementation as "SSN*".

SCENIC[@aibar_scenicsinglecellregulatory_2017] is a pipeline that consists of four main steps. Step 1: classical network inference is performed with arboreto, which is similar to GENIE3[@huynh-thu_inferringregulatorynetworks_2010]. Step 2: select the top 10 regulators per target. Interactions are grouped together in 'modules'; each module contains one regulator and all of its targets. Step 3: filter the modules using motif analysis. Step 4: for each cell, determine an activity score of each module using AUCell. As a post-processing of this output, all modules and the corresponding activity scores are combined back into a casewise GRN consisting of (cell, regulator, target, score) pairs. For this analysis, the Python implementation of SCENIC was used, namely pySCENIC. Since dyngen does not generate motif data, step 3 in this analysis is skipped.

The AUROC and AUPR metrics are common metrics for evaluating a predicted GRN with a ground-truth GRN. To compare a predicted casewise GRN with the ground-truth casewise GRN, the top 10'000 interactions per cell were retained. For each cell-specific network, the AUROC and AUPR were calculated.
## Comparison of RNA velocity methods {#sec:dyngen-velcompare}

15 datasets were generated with 5 different backbones: linear, linear simple, bifurcating, cyclic, and disconnected. We extracted a ground truth RNA velocity by subtracting for each mRNA molecule the propensity of its production by the propensity of its degradation. If the expression of an mRNA will increase in the future, this value is positive, while it is negative if it is going to decrease. For each gene, we compared the ground truth velocity with the observed velocity by calculating the Spearman rank correlation.

We compared two RNA velocity methods. The velocyto method[@lamanno_rnavelocitysingle_2018], as implemented in the velocyto.py package, in which we varied the "assumption" parameter between "constant_unspliced" and "constant_velocity". The scvelo method[@bergen_generalizingrnavelocity_2019], as implemented in the python scvelo package (http://scvelo.de), in which we varied the "mode" parameter between "deterministic", "stochastic" and "dynamical". For both methods, we used the same normalized data as provided by dyngen, with no extra cell or feature filtering. We also matched the parameters between both methods as best as possible, i.e. the k parameter for smoothing was set to 20 for both methods.

To visualize the velocity on an embedding, we used the "velocity_embedding" function, implemented in the scvelo python package.
